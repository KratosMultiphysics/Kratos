extern "C" %{
/**
 *
 * @file zpotrf_sp1dplus.jdf
 *
 * PaRSEC 1D algorithm jdf for Cholesky factorization.
 *
 * @copyright 2016-2018 Bordeaux INP, CNRS (LaBRI UMR 5800), Inria,
 *                      Univ. Bordeaux. All rights reserved.
 *
 * @version 6.0.1
 * @author Mathieu Faverge
 * @date 2018-07-16
 * @precisions normal z -> s d c
 *
 **/
#include <parsec.h>
#include <parsec/data_distribution.h>
#include <parsec/private_mempool.h>
#include "common.h"
#include "solver.h"
#include "sopalin_data.h"
#include "pastix_zcores.h"
#include "pastix_zcuda.h"

%}

/* Globals
 */
descA        [type = "parsec_sparse_matrix_desc_t *" ]
sopalin_data [type = "sopalin_data_t *" ]

forced_pushout [type = "int" hidden = on default = "(0)" ]
datacode  [type = "SolverMatrix*"         hidden = on default = "(sopalin_data->solvmtx)"       ]
cblknbr   [type = "pastix_int_t"          hidden = on default = "(datacode->cblknbr - 1)"       ]
bloknbr   [type = "pastix_int_t"          hidden = on default = "(datacode->bloknbr - 2)"       ]
lowrank   [type = "pastix_lr_t"           hidden = on default = "(sopalin_data->solvmtx->lowrank)"]

p_work    [type = "parsec_memory_pool_t *"]
lwork     [type = "pastix_int_t"]

cpu_coefs [ type = "pastix_fixdbl_t *" hidden = on default = "&((*(sopalin_data->cpu_coefs))[PastixKernelGEMMCblk2d2d][0])" ]
gpu_coefs [ type = "pastix_fixdbl_t *" hidden = on default = "&((*(sopalin_data->gpu_coefs))[PastixKernelGEMMCblk2d2d][0])" ]

/**************************************************
 *                   POTRF                        *
 * panel factorization: do trf of diagonal and    *
 *                    : trsm on off-diagonal      *
 **************************************************/
POTRF(k) [high_priority = on]

// Execution space
k = 0 .. cblknbr

browk0    = %{ SolverCblk *cblk = datacode->cblktab + k;     return cblk->brownum; %}
browk1    = %{ SolverCblk *cblk = datacode->cblktab + k + 1; return cblk->brownum; %}
lastbrow  = %{ if ( browk0 == browk1 ) return 0; else return datacode->browtab[ browk1 - 1 ]; %}
firstblok = %{ SolverCblk *cblk = datacode->cblktab + k;     return cblk->fblokptr - datacode->bloktab + 1; %}
lastblok  = %{ SolverCblk *cblk = datacode->cblktab + k + 1; return cblk->fblokptr - datacode->bloktab - 1; %}

// Parallel partitioning
:descA(0, k, 0)

// Parameters
/* C is A(k) if it's a leaf or get the cblk from the last update */
RW L <- ( browk0 == browk1 ) ? descA(0, k, 0) : C GEMM1D( lastbrow )
     -> A GEMM1D(firstblok .. lastblok)
     -> descA(0, k, 0)

; %{ return cblknbr - k; %}

BODY
{
    SolverCblk *cblk = datacode->cblktab + k;
    if (!(cblk->cblktype & CBLK_IN_SCHUR)) {
        cpucblk_zpotrfsp1d_panel( datacode, cblk, L );
    }
}
END

/**
 *       GEMM
 *
 * To have a contiguous range of GEMM to release in the potrf, they are numbered
 * with the indexes of the off-diagonal blocks, diagonal block included.
 * Thus, the diagonal block tasks which doesn't perfom computations are used as
 * DATA_IN tasks. This is mandatory when using the GPU, due to the versioning
 * bumped by the cpu version of the diagonal block that coccurs when computing
 * the diagonal blocks.
 *
 * For all off-diagonal blocks, it updates the trailing matrix with the panel
 * k-th block updating corresponding.
 *
 */
GEMM1D(bloknum)

// Execution space
bloknum = 1 .. bloknbr

lcblknm = %{ SolverBlok *blok = datacode->bloktab + bloknum;     return blok->lcblknm; %}
fcblknm = %{ SolverBlok *blok = datacode->bloktab + bloknum;     return blok->fcblknm; %}
first   = %{ SolverCblk *cblk = datacode->cblktab + fcblknm;     return cblk->brownum; %}
last    = %{ SolverCblk *cblk = datacode->cblktab + fcblknm + 1; return cblk->brownum - 1; %}

brownum = %{ return datacode->bloktab[bloknum].browind; %} /* -1 if diagonal block */
prev    = %{
    assert( first >= 0 );
    /**
     * If bloknum is a diagonal block, or if it is the first one applied on C,
     * there is no previous
     */
    if ((brownum == -1) || (brownum == first) ) {
        return 0;
    }
    /**
     * Otherwise we return the previous block in the list of blocks facing fcblk
     */
    else {
        assert( brownum > first );
        return datacode->browtab[brownum-1];
    }
    %}
next    = %{
    /**
     * If we are on a diagonal blok, or if we are the last one, there is no next
     */
    if ((brownum == -1) || (brownum >= last) ){
        return 0;
    } else {
        return datacode->browtab[brownum+1];
    }
    %}

n  = %{ if (brownum == -1) return 0; else return blok_rownbr(datacode->bloktab + bloknum); %}
k  = %{ if (brownum == -1) return 0; else return cblk_colnbr(datacode->cblktab + lcblknm); %}
m  = %{ if (brownum == -1) return 0; else {
        if ((datacode->cblktab + lcblknm)->cblktype & CBLK_LAYOUT_2D) {
            return datacode->cblktab[lcblknm].stride - (datacode->bloktab[bloknum].coefind / k);
        } else {
            return datacode->cblktab[lcblknm].stride - datacode->bloktab[bloknum].coefind;
        }
    }%}

// Parallel partitioning
:descA(0, fcblknm, 0)

// Parameters
READ  A  <- (brownum != -1) ? L POTRF( lcblknm ) : NULL

RW    C  <- (brownum == -1) ? NULL
         <- (brownum != -1) && (brownum == first) ? descA( 0, fcblknm, 0 )
         <- (brownum != -1) && (brownum != first) ? C GEMM1D( prev )

         -> (brownum != -1) && (brownum == last)  ? L POTRF( fcblknm )
         -> (brownum != -1) && (brownum != last)  ? C GEMM1D( next )

; %{ return cblknbr - ((fcblknm + lcblknm) / 2 ) + last - brownum; %}

BODY [ type=CUDA
       pushout=forced_pushout
       device=%{ SolverCblk *lcblk = datacode->cblktab + lcblknm;
                 SolverCblk *fcblk = datacode->cblktab + fcblknm;
                 if ( (brownum == -1) ||
                      (lcblk->cblktype & (CBLK_COMPRESSED | CBLK_IN_SCHUR)) ||
                      (fcblk->cblktype & CBLK_COMPRESSED) )
                 {
                     return -2;
                 } else {
                     return -1;
                 }
                 %}
       weight="(last-brownum+1)"
       cpu_cost="modelsGetCost3Param( cpu_coefs, m, n, k )"
       gpu_cost="modelsGetCost3Param( gpu_coefs, m, n, k )" ]
#if defined(PASTIX_WITH_CUDA)
{
    /* Never execute the GPU kernel on diagonal blocks */
    if (brownum != -1) {
        SolverCblk *lcblk = datacode->cblktab + lcblknm;
        SolverCblk *fcblk = datacode->cblktab + fcblknm;
        SolverBlok *blok  = datacode->bloktab + bloknum;

        assert( !(lcblk->cblktype & CBLK_COMPRESSED) &&
                !(fcblk->cblktype & CBLK_COMPRESSED) );

        if (!(lcblk->cblktype & CBLK_IN_SCHUR)) {
#if defined(PASTIX_CUDA_FERMI)
            gpu_zgemmsp_fermi( datacode,
                               PastixLower, PastixConjTrans,
                               descA->d_blocktab[parsec_body.index],
                               lcblk, blok, fcblk,
                               A, A, C,
                               parsec_body.stream );
#else
            gpucblk_zgemmsp( PastixLCoef, PastixLCoef, PastixConjTrans,
                             lcblk, blok, fcblk,
                             A, A, C,
                             &lowrank, parsec_body.stream );
#endif /* defined(PASTIX_CUDA_FERMI) */
        }
    }
}
#endif
END

BODY
{
    /* If diagonal block, we skip it */
    if (brownum != -1) {
        SolverCblk *lcblk = datacode->cblktab + lcblknm;
        SolverCblk *fcblk = datacode->cblktab + fcblknm;
        SolverBlok *blok  = datacode->bloktab + bloknum;
        pastix_complex64_t *work = NULL;

        if (!(lcblk->cblktype & CBLK_IN_SCHUR)) {
            if ( lwork > 0 ) {
                work = (pastix_complex64_t *)parsec_private_memory_pop( p_work );
            }

            cpucblk_zgemmsp( PastixLCoef, PastixLCoef, PastixConjTrans,
                             lcblk, blok, fcblk,
                             A, A, C,
                             work, lwork, &lowrank );

            if ( work  ) {
                parsec_private_memory_push( p_work, (void *)work );
            }
        }
    }
}
END
